# -*- coding: utf-8 -*-
"""Project6 part1

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1v4iDrQL4D70oeAvJSfJo_FUCelyCTPVI
"""

##to upload a csv file from mydrive
from google.colab import drive
drive.mount('/content/drive')

##import pandas and numpy
import pandas as pd
import numpy as np

##upload a CSv file
dataset_1=pd.read_csv('/content/drive/MyDrive/store.csv')#load first dataset in CSV format
dataset_1.head()

##upload a CSv file
dataset_1_train_data=pd.read_csv('/content/drive/MyDrive/train.csv')#load first dataset in CSV format
dataset_1_train_data.head()

##check the shape of dataset_1_train_data
dataset_1_train_data.shape

merged_train_and_store_data = pd.merge(dataset_1, dataset_1_train_data, how='inner', on='Store')

##check the shape of data
merged_train_and_store_data.shape

#now will check the data info
merged_train_and_store_data.info()

"""

> ### Handling missing value and filling the missing data in the data sheet

"""

##check missing values in the data set
merged_train_and_store_data.isnull().sum()



##check the unique values in CompetitionOpenSinceMonth
merged_train_and_store_data['CompetitionOpenSinceMonth'].unique()

merged_train_and_store_data['CompetitionOpenSinceYear'] = merged_train_and_store_data.groupby('StoreType')['CompetitionOpenSinceYear'].transform(lambda x: x.fillna(x.median()))
merged_train_and_store_data['CompetitionOpenSinceMonth'] = merged_train_and_store_data.groupby('StoreType')['CompetitionOpenSinceMonth'].transform(lambda x: x.fillna(x.median()))

#now will check the data of CompetitionOpenSinceMonth
merged_train_and_store_data['CompetitionOpenSinceMonth'].unique()

#now will check the data of CompetitionOpenSinceYear
merged_train_and_store_data['CompetitionOpenSinceYear'].unique()

##now conver the CompetitionOpenSinceMonth into int format
merged_train_and_store_data['CompetitionOpenSinceMonth']=merged_train_and_store_data['CompetitionOpenSinceMonth'].astype(int)
merged_train_and_store_data['CompetitionOpenSinceYear']=merged_train_and_store_data['CompetitionOpenSinceYear'].astype(int)

"""NOw will fill the missing values under Promo2SinceWeek, Promo2SinceYear and PromoInterval

Description:
Promo2Since[Year/Week] - describes the year and calendar week when the store
started participating in Promo2

PromoInterval - describes the consecutive intervals Promo2 is started, naming the
months the promotion is started anew. E.g. "Feb,May,Aug,Nov" means each round
starts in February, May, August, November of any given year for that store
"""

##check the unique values under Promo2SinceWeek
merged_train_and_store_data['Promo2SinceWeek'].unique()



## check the unique values in Promo2SinceYear
merged_train_and_store_data['Promo2SinceYear'].unique()

merged_train_and_store_data['Promo2SinceYear'] = merged_train_and_store_data.groupby('StoreType')['Promo2SinceYear'].transform(lambda x: x.fillna(x.median()))
merged_train_and_store_data['Promo2SinceWeek'] = merged_train_and_store_data.groupby('StoreType')['Promo2SinceWeek'].transform(lambda x: x.fillna(x.median()))

##check missing values under PromoInterval
merged_train_and_store_data['PromoInterval'].unique()



#now will conver this into intiger form
month_groups = {
    'Jan,Apr,Jul,Oct': 1,
    'Feb,May,Aug,Nov': 2,
    'Mar,Jun,Sept,Dec': 3
}

merged_train_and_store_data['MonthGroup'] = merged_train_and_store_data['PromoInterval'].map(month_groups)

##check missing values under PromoInterval
merged_train_and_store_data['MonthGroup'].unique()



##check the value count in MonthGroup
merged_train_and_store_data['MonthGroup'].value_counts()

##check the median of MonthGroup
merged_train_and_store_data['MonthGroup'].median()

## fill the missing values by medien
merged_train_and_store_data['MonthGroup'] = merged_train_and_store_data['MonthGroup'].fillna(merged_train_and_store_data['MonthGroup'].median())

##check the null value in dataset
merged_train_and_store_data.isnull().sum()

#shape of data
merged_train_and_store_data.shape

##We will chnag the name of colmn of MonthGroup to MonthGroup_PromoInterval
merged_train_and_store_data.rename(columns={'MonthGroup': 'MonthGroup_PromoInterval'}, inplace=True)

##Now will drop the column PromoInterval as we have coverted it as MonthGroup_PromoInterval
merged_train_and_store_data.drop('PromoInterval', axis=1, inplace=True)

##now agian check the info of data
merged_train_and_store_data.info()



##now convert these columns Promo2SinceWeek,  Promo2SinceYear, MonthGroup_PromoInterval  into int
merged_train_and_store_data['Promo2SinceWeek']=merged_train_and_store_data['Promo2SinceWeek'].astype(int)
merged_train_and_store_data['Promo2SinceYear']=merged_train_and_store_data['Promo2SinceYear'].astype(int)
merged_train_and_store_data['MonthGroup_PromoInterval']=merged_train_and_store_data['MonthGroup_PromoInterval'].astype(int)

##Now again check the info
merged_train_and_store_data.info()

##now check unique values of CompetitionDistance
merged_train_and_store_data['CompetitionDistance'].unique()

##Now fill the missing values in CompetitionDistance by mean
merged_train_and_store_data['CompetitionDistance'] = merged_train_and_store_data['CompetitionDistance'].fillna(merged_train_and_store_data['CompetitionDistance'].mean())

##check the unique value in store type
merged_train_and_store_data['StoreType'].unique()

##conver the object in to int
merged_train_and_store_data['StoreType'] = merged_train_and_store_data['StoreType'].map({'a': 1, 'b': 2, 'c': 3, 'd': 4})

##check the unique values in Assortment
merged_train_and_store_data['Assortment'].unique()

##conver the object in to int
merged_train_and_store_data['Assortment'] = merged_train_and_store_data['Assortment'].map({'a': 1, 'b': 2, 'c': 3})

##now check the data describe
merged_train_and_store_data.describe()

"""As per the above sheet, we can see the most outliers and skewed data in column CompetitionDistance"""

##check the data info
merged_train_and_store_data.info()

##check outliers in CompetitionDistance
import seaborn as sns
sns.boxplot(dataset_1['CompetitionDistance'])

##remove outliers
from scipy import stats
merged_train_and_store_data['CompetitionDistance']=np.log(merged_train_and_store_data['CompetitionDistance'])

##check outliers in CompetitionDistance
import seaborn as sns
sns.boxplot(merged_train_and_store_data['CompetitionDistance'])

#now again check the data
merged_train_and_store_data.describe()

##check the shape of data
merged_train_and_store_data.shape

""" Uploading the test data"""

##upload a CSv file
#dataset_1_test_data=pd.read_csv('/content/drive/MyDrive/test.csv')#load first dataset in CSV format
#dataset_1_test_data.head()

##checkthe datainfor
#dataset_1_test_data.info()

#merged_TESt_and_store_data = pd.merge(dataset_1, dataset_1_test_data, how='inner', on='Store')

#now check the shape of data
#merged_TESt_and_store_data.shape

##check missing values
#merged_TESt_and_store_data.isnull().sum()

##

"""##uploading  the test data

"""

##upload a CSv file
dataset_3_test=pd.read_csv('/content/drive/MyDrive/test.csv')#load first dataset in CSV format
dataset_3_test.head()



"""# **EDA** **part**

EDA to Check for distribution in both training and test sets - are the promotions
distributed similarly between these two groups?
"""

##check the plot promo in train data
plt.figure(figsize=(4,2), dpi = 150)
sns.countplot(merged_train_and_store_data, x = 'Promo')
plt.title('Distribution of Promotion in train set')
plt.xticks([0,1], ['No','Yes'])
plt.show()

##check the plot promo in test data
plt.figure(figsize=(4,2), dpi = 150)
sns.countplot(dataset_3_test, x = 'Promo')
plt.title('Distribution of Promotion in test set')
plt.xticks([0,1], ['No','Yes'])
plt.show()

##check promo distrubution vs sales
sns.barplot(x='Promo',y='Sales',data=merged_train_and_store_data)



##check the plot Customers	and sales
sns.barplot(x='Customers',y='Sales',data=merged_train_and_store_data)

import matplotlib.pyplot as plt
sns.scatterplot(x='Customers', y='Sales', data=merged_train_and_store_data)
plt.title('Correlation Between Sales and Number of Customers')
plt.show()

"""Observations:

Positive Correlation: The graph suggests a positive correlation between the number of customers and sales.

Linearity: The scatter plot seems to suggest a linear relationship, though it might be worth calculating the correlation coefficient to confirm this. If the relationship is linear, a simple linear regression could be a good model to predict sales based on the number of customers.
"""





##sales when open
sns.barplot(x='Open',y='Sales',data=merged_train_and_store_data)

"""Check & compare sales behavior before, during and after holidays"""

plt.figure(figsize=(15,6))
sns.heatmap(merged_train_and_store_data.corr(numeric_only=True), annot=True)

"""Sales and Customers: There's a strong positive correlation between the number of customers and sales. This means that as the number of customers increases, sales also tend to increase.

Promo and Sales: Promotions have a positive correlation with sales, indicating that promotional activities help boost sales.

DayOfWeek and Sales: The day of the week shows a moderate correlation with sales, suggesting that sales vary on different days of the week.
"""



"""Now will check



*   Check & compare sales behavior before, during and after holidays
*    Find out any seasonal (Christmas, Easter etc) purchase behaviours,


"""

##check unique values in StateHoliday
merged_train_and_store_data['StateHoliday'].unique()

"""StateHoliday - indicates a state holiday. Normally all stores, with few exceptions, are
closed on state holidays. Note that all schools are closed on public holidays and
weekends. a = public holiday, b = Easter holiday, c = Christmas, 0 = None
"""

plt.figure(figsize=(8,4))
sns.barplot(merged_train_and_store_data, x='StateHoliday', y='Sales')
plt.title('Sales with respect of State Holidays')
plt.xticks([0,1,2,3],['None','Public Holiday','Easter Holiday','Christmas'])
plt.show()

plt.figure(figsize=(8,4))
sns.barplot(merged_train_and_store_data, x='SchoolHoliday', y='Sales')
plt.title('Sales with respect of School Holidays')
plt.show()

import matplotlib.pyplot as plt
import seaborn as sns
plt.figure(figsize=(5,2), dpi=200)
sns.kdeplot(merged_train_and_store_data['CompetitionDistance']/1000)
plt.title('Competition Distance Distribution in km')
plt.show()

"""**Check for distribution in both training and test sets - are the promotions distributed similarly between these two groups?**"""

plt.figure(figsize=(4,2), dpi = 200)
sns.countplot(merged_train_and_store_data, x = 'Promo')
plt.title('Distribution of Promotion in train set')
plt.xticks([0,1], ['No','Yes'])
plt.show()

plt.figure(figsize=(4,2), dpi = 200)
sns.countplot(dataset_3_test, x = 'Promo')
plt.title('Distribution of Promotion in test set')
plt.xticks([0,1], ['No','Yes'])
plt.show()

"""#####Promotion in training and testing set is NOT similarly distributed

**checking  and coverting Date column data into time series data**
"""

##check the data in date column
merged_train_and_store_data['Date']

merged_train_and_store_data["Date"]=pd.to_datetime(merged_train_and_store_data["Date"])
merged_train_and_store_data["Day"]=merged_train_and_store_data["Date"].dt.day
merged_train_and_store_data["Week"]=merged_train_and_store_data["Date"].dt.isocalendar().week
merged_train_and_store_data["Month"]=merged_train_and_store_data["Date"].dt.month
merged_train_and_store_data["Year"]=merged_train_and_store_data["Date"].dt.year

dataset_3_test["Date"]=pd.to_datetime(dataset_3_test["Date"])
dataset_3_test["Day"]=dataset_3_test["Date"].dt.day
dataset_3_test["Week"]=dataset_3_test["Date"].dt.isocalendar().week
dataset_3_test["Month"]=dataset_3_test["Date"].dt.month
dataset_3_test["Year"]=dataset_3_test["Date"].dt.year

print("Train")
train_min = merged_train_and_store_data['Date'].min()
print(f"min {train_min}")

train_max = merged_train_and_store_data['Date'].max()
print(f"max {train_max}")

print(f"delta: {train_max - train_min}")

print("\nTest")

test_min = dataset_3_test['Date'].min()
print(f"min {test_min}")

test_max = dataset_3_test['Date'].max()
print(f"max {test_max}")

print(f"delta: {test_max - test_min}")

# Define the start and end dates for the training and test sets
train_start_date = train_min
train_end_date = train_max

test_start_date = test_min
test_end_date = test_max

# Create the plot
plt.figure(figsize=(10, 5))

# Plot the training set duration
plt.plot([train_start_date, train_end_date], [1, 1], label='Training Set', color='blue')

# Plot the test set duration
plt.plot([test_start_date, test_end_date], [2, 2], label='Test Set', color='red')

# Set plot title and labels
plt.title('Timeline of Training and Test Sets')
plt.xlabel('Date')
plt.ylabel('Dataset')
plt.yticks([1, 2], ['Training Set', 'Test Set'])

# Add legend
plt.legend()

# Show the plot
plt.grid(True)
plt.tight_layout()
plt.show()

merged_train_and_store_data.isnull().sum()

##check data descp
merged_train_and_store_data.describe()

##now remove outliers in sales
Q1 = merged_train_and_store_data['Sales'].quantile(0.25)
Q3 = merged_train_and_store_data['Sales'].quantile(0.75)
IQR = Q3-Q1
outliers = merged_train_and_store_data[(merged_train_and_store_data['Sales'] < (Q1 - 1.5*IQR)) | (merged_train_and_store_data['Sales'] > (Q3 + 1.5*IQR))]
outliers

plt.figure(figsize = (15,3), dpi = 200)
outliers.plot(kind = 'box', color = 'red')
plt.xticks(rotation = 90)
plt.title('Total Outliers', color = 'red')
plt.show()

plt.figure(figsize=(5,2), dpi=200)
sns.kdeplot(merged_train_and_store_data['CompetitionDistance']/1000)
plt.title('Competition Distance Distribution in km')
plt.show()

sns.catplot(data = merged_train_and_store_data, x='Month', y='Sales', col ='Promo', hue='Promo2', row='Year', kind="bar")
plt.title('Sale of each year in promotion breakdown')
plt.show()

#Sales weekly
plt.figure(figsize=(12, 4))
plt.scatter(merged_train_and_store_data["Week"],merged_train_and_store_data["Sales"])
plt.title('Sales per week')
plt.plot()

#Sales monthly
plt.figure(figsize=(12, 4))
plt.scatter(merged_train_and_store_data["Month"],merged_train_and_store_data["Sales"])
plt.title('Sales per month')
plt.plot()

#Open_DayOfWeek
plt.figure(figsize=(15,4))
sns.countplot( x='Day', data=merged_train_and_store_data, hue="Open", palette="Set1")
plt.title('Sales on daily basis')
plt.show()

"""Almost all the stores are closed at the weekend."""

fig, axes = plt.subplots(2, 2, figsize=(15, 10))
sns.barplot(x='Year',y="Sales", data=merged_train_and_store_data, ax=axes[0, 0], color = 'salmon')
sns.barplot(x='Month',y="Sales", data=merged_train_and_store_data, ax=axes[0, 1], color = 'skyblue')
sns.barplot(x='Day',y="Sales", data=merged_train_and_store_data, ax=axes[1, 0], color = 'brown')
sns.barplot(x='DayOfWeek',y="Sales", data=merged_train_and_store_data, ax=axes[1, 1], color = 'pink')

# Set the titles for each chart
axes[0, 0].set_title('Sales by Year')
axes[0, 1].set_title('Sales by Month')
axes[1, 0].set_title('Sales by Day')
axes[1, 1].set_title('Sales by Weekday')

# Adjust the spacing between subplots
plt.tight_layout()

# Show the grid of bar charts
plt.show()



